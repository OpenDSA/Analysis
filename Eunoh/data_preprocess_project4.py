# -*- coding: utf-8 -*-
"""Data preprocess project4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gBbkcT_r12aCO2dZ2Zx7r_Qwpz4Ic1OT
"""

from google.colab import drive
drive.mount('/content/drive')

import sys
# modify "customized_path_to_homework", path of folder in drive, where you uploaded your homework
customized_path_to_homework = "/content/drive/My Drive/research data_actual"
sys.path.append(customized_path_to_homework)

import pandas as pd
import matplotlib.pyplot as plt

original = pd.read_excel("/content/drive/My Drive/research data_actual/Project4_Origin.xlsx")
sB = pd.read_excel("/content/drive/My Drive/research data_actual/Project4_StrugglingBean.xlsx")

distribution = original.distribution

import collections
counter=collections.Counter(distribution * 10)
print(counter)

plt.bar(counter.keys(), counter.values(), width = 6)
plt.ylim(0, 140)
plt.xlabel("Grade of project4")
plt.ylabel('Number of students')
counter.values()

survey = pd.read_excel("/content/drive/My Drive/research data_actual/SurveyData.xlsx")
survey

surDis1 = survey.Q8.astype(str)
counter2=collections.Counter(surDis1)
print(counter2)

surDis = survey.Q8.astype(str)

counter1=collections.Counter(surDis)
print(counter1)

plt.bar(counter1.keys(), counter1.values())
plt.xlabel("How difficult was the project?")
plt.ylabel('Number of students')
counter1.values()

surveyTemp = pd.read_excel("/content/drive/My Drive/research data_actual/SurveyData.xlsx")

"""survey data preprocessing from string to int"""

from re import A
def categorize_grade(aDataobj):
  if ('90 and above') in aDataobj :
    return 1
  elif('80-89') in aDataobj:
    return 2
  elif('70-79') in aDataobj:
    return 3
  elif('60-69') in aDataobj:
    return 4
  elif('Below 60') in aDataobj:
    return 5

def categorize_helpTA(aDataobj):
  if ('None') in aDataobj :
    return 1
  elif('5 or less') in aDataobj:
    return 2
  elif('6 to 10') in aDataobj:
    return 3
  elif('More than 10 times') in aDataobj:
    return 4
def categorize_lecture(aDataobj):
  if ('all lectures.') in aDataobj :
    return 1
  elif('most lectures.') in aDataobj:
    return 2
  elif('more than half the lectures.') in aDataobj:
    return 3
  elif('less than half the lectures.') in aDataobj:
    return 4
  elif('only a few lectures.') in aDataobj:
    return 5
def categorize_interactionHelped(aDataobj):
  if ('Strongly Agree') in aDataobj :
    return 1
  elif('Agree') in aDataobj:
    return 2
  elif('Disagree') in aDataobj:
    return 3
  elif('Strongly Disagree') in aDataobj:
    return 4

def categorize_outsideSource(aDataobj):
  if ('None') in aDataobj :
    return 1
  elif('5 or less') in aDataobj:
    return 2
  elif('6 to 10') in aDataobj:
    return 3
  elif('More than 10 times') in aDataobj:
    return 4

def categorize_difficultness(aDataobj):
  if ('Easy') in aDataobj :
    return 1
  elif('Not difficult') in aDataobj:
    return 2
  elif('Difficult') in aDataobj:
    return 3
  elif('Very difficult') in aDataobj:
    return 4

def categorize_sufficientHelp(aDataobj):
  if ('Strongly Agree') in aDataobj :
    return 1
  elif('Agree') in aDataobj:
    return 2
  elif('Disagree') in aDataobj:
    return 3
  elif('Strongly Disagree') in aDataobj:
    return 4

surveyTemp['Q6'] = survey['Q6'].apply(categorize_grade)
surveyTemp['Q11'] = survey['Q11'].apply(categorize_helpTA)
surveyTemp['Q4'] = survey['Q4'].apply(categorize_lecture)
surveyTemp['Q14'] = survey['Q14'].apply(categorize_interactionHelped)
surveyTemp['Q10'] = survey['Q10'].apply(categorize_outsideSource)
surveyTemp['Q8'] = survey['Q8'].apply(categorize_difficultness)
surveyTemp['Q13'] = survey['Q13'].apply(categorize_sufficientHelp)

surveyTemp

hp = pd.read_excel("/content/drive/My Drive/research data_actual/above80.xlsx")
lp = pd.read_excel("/content/drive/My Drive/research data_actual/less80.xlsx")
lp2 = pd.read_excel("/content/drive/My Drive/research data_actual/less80_2.xlsx")
hp

difficultHp = hp.Q8.astype(str)
difficultLp = lp2.Q8.astype(str)

difficultLp

counterHP = collections.Counter(difficultHp)
print(counterHP)

counterLP =collections.Counter(difficultLp)
print(counterLP)

# # evaluate a logistic regression model using k-fold cross-validation
# from numpy import mean
# from numpy import std
# from sklearn.datasets import make_classification
# from sklearn.model_selection import KFold
# from sklearn.model_selection import cross_val_score
# from sklearn.linear_model import LogisticRegression
# # create dataset
# X = temp.
# X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1)
# # prepare the cross-validation procedure
# cv = KFold(n_splits=5, random_state=1, shuffle=True)
# # create model
# model = LogisticRegression()
# # evaluate model
# scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# # report performance
# print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))



