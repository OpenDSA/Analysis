# -*- coding: utf-8 -*-
"""cs5040 analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jSIYMRWAV7qw8sZtn8gvqqVDDJzQ6pga
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
import sys
customized_path_to_homework = "/content/gdrive/My Drive/Research"
sys.path.append(customized_path_to_homework)
import os, sys
import pandas as pd
import numpy as np
import matplotlib.mlab as mlab
import matplotlib.pyplot as plt
from datetime import datetime as dt, timedelta
import warnings
import seaborn as sns
sys.path.insert(0,'../')
# %load_ext autoreload
# %autoreload 2
warnings.filterwarnings('ignore')

file_name = "cs5040_fall_2020"

fall_abstracted_data = pd.read_csv("/content/gdrive/My Drive/Research/" + file_name + "_merged_result_unannotated.csv")
fall_sorted_data = pd.read_csv("/content/gdrive/My Drive/Research/" + file_name + "_sorted.csv")
fall_abstracted_data = fall_abstracted_data[ (fall_abstracted_data['user ID'] != 58) & (fall_abstracted_data['user ID'] != 1090) ]
fall_sorted_data = fall_sorted_data[ (fall_sorted_data['user_id'] != 58) & (fall_sorted_data['user_id'] != 1090) ]

spring_file_name = "cs5040_spring_2021"
spring_abstracted_data = pd.read_csv("/content/gdrive/My Drive/Research/" + spring_file_name + "_merged_result_unannotated.csv")
spring_sorted_data = pd.read_csv("/content/gdrive/My Drive/Research/" + spring_file_name + "_sorted.csv")
spring_abstracted_data = spring_abstracted_data[ (spring_abstracted_data['user ID'] != 58) & (spring_abstracted_data['user ID'] != 1090) ]
spring_sorted_data = spring_sorted_data[ (spring_sorted_data['user_id'] != 58) & (spring_sorted_data['user_id'] != 1090) ]

cs5040_abstracted = pd.concat([fall_abstracted_data, spring_abstracted_data])
cs5040_sorted = pd.concat([fall_sorted_data, spring_sorted_data], ignore_index=True)

# Remove duplicated entires
cs5040_sorted = cs5040_sorted.drop_duplicates(subset=['action_time', 'short_name', 'user_id'], keep=False)

cs5040_sorted['action_time'] = pd.to_datetime(cs5040_sorted['action_time']) 
cs5040_sorted['delta_time'] = cs5040_sorted[cs5040_sorted['ex_type'] == 'ss'].groupby(['user_id', 'short_name'])['action_time'].diff()
cs5040_sorted[cs5040_sorted['ex_type'] == 'ss']
cs5040_sorted['delta_time'] = cs5040_sorted['delta_time'].dt.total_seconds()
less_than_15 = cs5040_sorted[cs5040_sorted['delta_time'] < 15]

"""Reading time distribution"""

threshold = 30
p = cs5040_sorted['delta_time'].plot.hist(bins= 60, range=(0, 30))
cs5040_sorted['delta_time'].describe()

"""Top 6 modules students completed"""

exercises = cs5040_sorted[cs5040_sorted['ex_type'] == "ss"]
print(cs5040_sorted[cs5040_sorted['inst_chapter_module_id'] == 79785.0]['description'])
exercises.groupby('inst_chapter_module_id')['user_id'].nunique().reset_index(name='count').sort_values(['count'], ascending=False).head(10)

between_8_and_15 = cs5040_sorted[ (cs5040_sorted['delta_time'] <= 15 ) & (cs5040_sorted['delta_time'] >= 8) ]

cs5040_abstracted
rm_duplicated = cs5040_abstracted.drop_duplicates(subset=['Start time', 'End Time', 'user ID'], keep=False)
rm_duplicated

seq1 = np.asarray(['document event', 'FF event'])
seq2 = np.asarray(['document event', 'PE event'])
seq3 = np.asarray(['Window open', 'FF event'])
seq4 = np.asarray(['window event', 'PE event'])

N = len(seq1)

def rolling_window(a, window):
  shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
  strides = a.strides + (a.strides[-1],)
  c = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
  return c

arr = rm_duplicated['Event name'].values
b = np.all( (rolling_window(arr, N) == seq1) | (rolling_window(arr, N) == seq2) | (rolling_window(arr, N) == seq3) | (rolling_window(arr, N) == seq4), axis = 1)
c = np.mgrid[0:len(b)][b]

d = [i for x in c for i in range(x, x + N)]
rm_duplicated['seq_count'] = np.in1d(np.arange(len(arr)), d)

"""Behavior 1 Activity Sessions Behavior"""

print((rm_duplicated[rm_duplicated['seq_count'] == True].groupby('user ID')['user ID'].count() / 2).index)
print((rm_duplicated[rm_duplicated['seq_count'] == True].groupby('user ID')['user ID'].count() / 2).values)
rm_duplicated[ (rm_duplicated['Action Time'].isnull() == False) & (rm_duplicated['Action Time'].str.contains('Reading'))]

"""Behavior 2 (15 <= Reading time <= 120 & must be in sequence)"""

behavior2 = rm_duplicated[ (rm_duplicated['Action Time'].str.contains('Reading time') == True) & (rm_duplicated['seq_count'] == True) ]
behavior2
behavior2['Action Time'] = behavior2['Action Time'].str[13:-3].astype(float)
behavior2 = behavior2[ (behavior2['Action Time'] > 0) ] # Ignore reading time less than 1 second
behavior2

behavior2_between_ranges = behavior2[ (behavior2['Action Time'] >= 15) & (behavior2['Action Time'] <= 90) ] # reading time ranges between 6 and 26 seconds
print(behavior2_between_ranges.groupby('user ID')['user ID'].count().index)   
print(behavior2_between_ranges.groupby('user ID')['user ID'].count().values)

# Plotting
print(behavior2['Action Time'].describe())
p = behavior2['Action Time'].plot.hist(bins = 70, range = (0, 140), figsize=(10,5) )
p.set_xticks(range(0, 150, 10))
p.set_title(file_name)
p.set_xlabel("Reading time in seconds")
p.set_ylabel("Number of Instances")

b2 = cs5040_abstracted[cs5040_abstracted['Action Time'].str.contains("Reading time") == True]
b2['Action Time'] = b2['Action Time'].str[13:-3].astype(float)
temp = b2[b2['Action Time'] > 1]
temp
# p = temp['Action Time'].plot.hist(bins = 60, range = (0, 600), figsize=(30,5))
# p.set_xlabel("Reading Time (seconds)")
# p.set_ylabel("Number of Instances")
# temp['Action Time'].describe()

"""Behavior 3 Credit Seeking Slideshow less than 15 sec"""

less_than_15

print(less_than_15.groupby('user_id')['user_id'].count().index)
print(less_than_15.groupby('user_id')['user_id'].count().values)